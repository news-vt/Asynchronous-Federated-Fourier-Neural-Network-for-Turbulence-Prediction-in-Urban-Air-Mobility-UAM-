{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqyOSRnQMUjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63121a31-ee5e-414e-89cf-f3ddd09307a8"
      },
      "source": [
        "!pip install -q torch==1.7.1 torchvision"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 776.8MB 23kB/s \n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO0dggzOFJTH",
        "outputId": "e758e390-287f-4f20-ac48-6f50b4547be2"
      },
      "source": [
        "pip install Cython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (0.29.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JshPUfO0MZl5"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import h5py\n",
        "import sklearn.metrics\n",
        "import torch.nn as nn\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "\n",
        "#################################################\n",
        "#\n",
        "# Utilities\n",
        "#\n",
        "#################################################\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# reading data\n",
        "class MatReader(object):\n",
        "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
        "        super(MatReader, self).__init__()\n",
        "\n",
        "        self.to_torch = to_torch\n",
        "        self.to_cuda = to_cuda\n",
        "        self.to_float = to_float\n",
        "\n",
        "        self.file_path = file_path\n",
        "\n",
        "        self.data = None\n",
        "        self.old_mat = None\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            self.data = scipy.io.loadmat(self.file_path)\n",
        "            self.old_mat = True\n",
        "        except:\n",
        "            self.data = h5py.File(self.file_path)\n",
        "            self.old_mat = False\n",
        "\n",
        "    def load_file(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self._load_file()\n",
        "\n",
        "    def read_field(self, field):\n",
        "        x = self.data[field]\n",
        "\n",
        "        if not self.old_mat:\n",
        "            x = x[()]\n",
        "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
        "\n",
        "        if self.to_float:\n",
        "            x = x.astype(np.float32)\n",
        "\n",
        "        if self.to_torch:\n",
        "            x = torch.from_numpy(x)\n",
        "\n",
        "            if self.to_cuda:\n",
        "                x = x.cuda()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_cuda(self, to_cuda):\n",
        "        self.to_cuda = to_cuda\n",
        "\n",
        "    def set_torch(self, to_torch):\n",
        "        self.to_torch = to_torch\n",
        "\n",
        "    def set_float(self, to_float):\n",
        "        self.to_float = to_float\n",
        "\n",
        "# normalization, pointwise gaussian\n",
        "class UnitGaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(UnitGaussianNormalizer, self).__init__()\n",
        "\n",
        "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
        "        self.mean = torch.mean(x, 0)\n",
        "        self.std = torch.std(x, 0)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        if sample_idx is None:\n",
        "            std = self.std + self.eps # n\n",
        "            mean = self.mean\n",
        "        else:\n",
        "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
        "                std = self.std[sample_idx] + self.eps  # batch*n\n",
        "                mean = self.mean[sample_idx]\n",
        "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
        "                std = self.std[:,sample_idx]+ self.eps # T*batch*n\n",
        "                mean = self.mean[:,sample_idx]\n",
        "\n",
        "        # x is in shape of batch*n or T*batch*n\n",
        "        x = (x * std) + mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "\n",
        "# normalization, Gaussian\n",
        "class GaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(GaussianNormalizer, self).__init__()\n",
        "\n",
        "        self.mean = torch.mean(x)\n",
        "        self.std = torch.std(x)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        x = (x * (self.std + self.eps)) + self.mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "\n",
        "\n",
        "# normalization, scaling by range\n",
        "class RangeNormalizer(object):\n",
        "    def __init__(self, x, low=0.0, high=1.0):\n",
        "        super(RangeNormalizer, self).__init__()\n",
        "        mymin = torch.min(x, 0)[0].view(-1)\n",
        "        mymax = torch.max(x, 0)[0].view(-1)\n",
        "\n",
        "        self.a = (high - low)/(mymax - mymin)\n",
        "        self.b = -self.a*mymax + high\n",
        "\n",
        "    def encode(self, x):\n",
        "        s = x.size()\n",
        "        x = x.view(s[0], -1)\n",
        "        x = self.a*x + self.b\n",
        "        x = x.view(s)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x):\n",
        "        s = x.size()\n",
        "        x = x.view(s[0], -1)\n",
        "        x = (x - self.b)/self.a\n",
        "        x = x.view(s)\n",
        "        return x\n",
        "\n",
        "#loss function with rel/abs Lp loss\n",
        "class LpLoss(object):\n",
        "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
        "        super(LpLoss, self).__init__()\n",
        "\n",
        "        #Dimension and Lp-norm type are postive\n",
        "        assert d > 0 and p > 0\n",
        "\n",
        "        self.d = d\n",
        "        self.p = p\n",
        "        self.reduction = reduction\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def abs(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        #Assume uniform mesh\n",
        "        h = 1.0 / (x.size()[1] - 1.0)\n",
        "\n",
        "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(all_norms)\n",
        "            else:\n",
        "                return torch.sum(all_norms)\n",
        "\n",
        "        return all_norms\n",
        "\n",
        "    def rel(self, x, y):\n",
        "        num_examples = x.size()[0]\n",
        "\n",
        "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
        "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
        "\n",
        "        if self.reduction:\n",
        "            if self.size_average:\n",
        "                return torch.mean(diff_norms/y_norms)\n",
        "            else:\n",
        "                return torch.sum(diff_norms/y_norms)\n",
        "\n",
        "        return diff_norms/y_norms\n",
        "\n",
        "    def __call__(self, x, y):\n",
        "        return self.rel(x, y)\n",
        "\n",
        "# A simple feedforward neural network\n",
        "class DenseNet(torch.nn.Module):\n",
        "    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n",
        "        super(DenseNet, self).__init__()\n",
        "\n",
        "        self.n_layers = len(layers) - 1\n",
        "\n",
        "        assert self.n_layers >= 1\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        for j in range(self.n_layers):\n",
        "            self.layers.append(nn.Linear(layers[j], layers[j+1]))\n",
        "\n",
        "            if j != self.n_layers - 1:\n",
        "                if normalize:\n",
        "                    self.layers.append(nn.BatchNorm1d(layers[j+1]))\n",
        "\n",
        "                self.layers.append(nonlinearity())\n",
        "\n",
        "        if out_nonlinearity is not None:\n",
        "            self.layers.append(out_nonlinearity())\n",
        "\n",
        "    def forward(self, x):\n",
        "        for _, l in enumerate(self.layers):\n",
        "            x = l(x)\n",
        "\n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPTgCYS1MfA3",
        "outputId": "ab5872e6-432d-4279-daf8-f9258bc2194a"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.1\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxZtqyl9MgR4"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.parameter import Parameter\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import operator\n",
        "from functools import reduce\n",
        "from functools import partial\n",
        "from timeit import default_timer\n",
        "#from utilities3 import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUxL5g-sMmSH"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frEcoPdkMnl3"
      },
      "source": [
        "def compl_mul1d(a, b):\n",
        "    # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
        "    op = partial(torch.einsum, \"bix,iox->box\")\n",
        "    return torch.stack([\n",
        "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
        "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
        "    ], dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZgJiQz3Mo4H"
      },
      "source": [
        "class SpectralConv1d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, modes1):\n",
        "        super(SpectralConv1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
        "        \"\"\"\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
        "\n",
        "        self.scale = (1 / (in_channels*out_channels))\n",
        "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, 2))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.shape[0]\n",
        "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
        "        x_ft = torch.rfft(x, 1, normalized=True, onesided=True)\n",
        "\n",
        "        # Multiply relevant Fourier modes\n",
        "        out_ft = torch.zeros(batchsize, self.in_channels, x.size(-1)//2 + 1, 2, device=x.device)\n",
        "        out_ft[:, :, :self.modes1] = compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
        "\n",
        "        #Return to physical space\n",
        "        x = torch.irfft(out_ft, 1, normalized=True, onesided=True, signal_sizes=(x.size(-1), ))\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeOgsvi4MqkW"
      },
      "source": [
        "class SimpleBlock1d(nn.Module):\n",
        "    def __init__(self, modes, width):\n",
        "        super(SimpleBlock1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        The overall network. It contains 4 layers of the Fourier layer.\n",
        "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
        "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
        "            W defined by self.w; K defined by self.conv .\n",
        "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
        "\n",
        "        input: the solution of the initial condition and location (a(x), x)\n",
        "        input shape: (batchsize, x=s, c=2)\n",
        "        output: the solution of a later timestep\n",
        "        output shape: (batchsize, x=s, c=1)\n",
        "        \"\"\"\n",
        "\n",
        "        self.modes1 = modes\n",
        "        self.width = width\n",
        "        self.fc0 = nn.Linear(2, self.width) # input channel is 2: (a(x), x)\n",
        "\n",
        "        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
        "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
        "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(self.width, 128)\n",
        "        self.fc2 = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.fc0(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "\n",
        "        x1 = self.conv0(x)\n",
        "        x2 = self.w0(x)\n",
        "        x = x1 + x2\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.w1(x)\n",
        "        x = x1 + x2\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x1 = self.conv2(x)\n",
        "        x2 = self.w2(x)\n",
        "        x = x1 + x2\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x1 = self.conv3(x)\n",
        "        x2 = self.w3(x)\n",
        "        x = x1 + x2\n",
        "\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E9purL_MsTn"
      },
      "source": [
        "class Net1d(nn.Module):\n",
        "    def __init__(self, modes, width):\n",
        "        super(Net1d, self).__init__()\n",
        "\n",
        "        \"\"\"\n",
        "        A wrapper function\n",
        "        \"\"\"\n",
        "\n",
        "        self.conv1 = SimpleBlock1d(modes, width)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "    def count_params(self):\n",
        "        c = 0\n",
        "        for p in self.parameters():\n",
        "            c += reduce(operator.mul, list(p.size()))\n",
        "\n",
        "        return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R5y_9pKMt23"
      },
      "source": [
        "################################################################\n",
        "#  configurations\n",
        "################################################################\n",
        "ntrain = 1000\n",
        "ntest = 100\n",
        "\n",
        "sub = 2**3 #subsampling rate\n",
        "h = 2**13 // sub #total grid size divided by the subsampling rate\n",
        "s = h\n",
        "\n",
        "batch_size = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "rounds = 500\n",
        "step_size = 100\n",
        "gamma = 0.5\n",
        "\n",
        "modes = 16\n",
        "width = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAWD8IiVMvdH"
      },
      "source": [
        "# reading data\n",
        "class MatReaderMatReader(object):\n",
        "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
        "        super(MatReader, self).__init__()\n",
        "\n",
        "        self.to_torch = to_torch\n",
        "        self.to_cuda = to_cuda\n",
        "        self.to_float = to_float\n",
        "\n",
        "        self.file_path = file_path\n",
        "\n",
        "        self.data = None\n",
        "        self.old_mat = None\n",
        "        self._load_file()\n",
        "\n",
        "    def _load_file(self):\n",
        "        try:\n",
        "            self.data = scipy.io.loadmat(self.file_path)\n",
        "            self.old_mat = True\n",
        "        except:\n",
        "            self.data = h5py.File(self.file_path)\n",
        "            self.old_mat = False\n",
        "\n",
        "    def load_file(self, file_path):\n",
        "        self.file_path = file_path\n",
        "        self._load_file()\n",
        "\n",
        "    def read_field(self, field):\n",
        "        x = self.data[field]\n",
        "\n",
        "        if not self.old_mat:\n",
        "            x = x[()]\n",
        "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
        "\n",
        "        if self.to_float:\n",
        "            x = x.astype(np.float32)\n",
        "\n",
        "        if self.to_torch:\n",
        "            x = torch.from_numpy(x)\n",
        "\n",
        "            if self.to_cuda:\n",
        "                x = x.cuda()\n",
        "\n",
        "        return x\n",
        "\n",
        "    def set_cuda(self, to_cuda):\n",
        "        self.to_cuda = to_cuda\n",
        "\n",
        "    def set_torch(self, to_torch):\n",
        "        self.to_torch = to_torch\n",
        "\n",
        "    def set_float(self, to_float):\n",
        "        self.to_float = to_float\n",
        "\n",
        "# normalization, pointwise gaussian\n",
        "class UnitGaussianNormalizer(object):\n",
        "    def __init__(self, x, eps=0.00001):\n",
        "        super(UnitGaussianNormalizer, self).__init__()\n",
        "\n",
        "        # x could be in shape of ntrain*n or ntrain*T*n or ntrain*n*T\n",
        "        self.mean = torch.mean(x, 0)\n",
        "        self.std = torch.std(x, 0)\n",
        "        self.eps = eps\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = (x - self.mean) / (self.std + self.eps)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, sample_idx=None):\n",
        "        if sample_idx is None:\n",
        "            std = self.std + self.eps # n\n",
        "            mean = self.mean\n",
        "        else:\n",
        "            if len(self.mean.shape) == len(sample_idx[0].shape):\n",
        "                std = self.std[sample_idx] + self.eps  # batch*n\n",
        "                mean = self.mean[sample_idx]\n",
        "            if len(self.mean.shape) > len(sample_idx[0].shape):\n",
        "                std = self.std[:,sample_idx]+ self.eps # T*batch*n\n",
        "                mean = self.mean[:,sample_idx]\n",
        "\n",
        "        # x is in shape of batch*n or T*batch*n\n",
        "        x = (x * std) + mean\n",
        "        return x\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mean = self.mean.cuda()\n",
        "        self.std = self.std.cuda()\n",
        "    '''\n",
        "    def cpu(self):\n",
        "        self.mean = self.mean.cpu()\n",
        "        self.std = self.std.cpu()\n",
        "    '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftXaKXBHMw33"
      },
      "source": [
        "dataloader = MatReader('/content/drive/MyDrive/Colab Notebooks/Burgers_R10/burgers_data_R10.mat')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCPWMXVSMy53"
      },
      "source": [
        "x_data = dataloader.read_field('a')[:,::sub]\n",
        "y_data = dataloader.read_field('u')[:,::sub]\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6jpnM7ffrLh"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDl__EVEBpP7",
        "outputId": "637f1952-2a36-486d-f314-04edb0db0f79"
      },
      "source": [
        "x_data.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2048, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYp9PI8Y0Rmu"
      },
      "source": [
        "[a,b] = x_data.size()\n",
        "a_index_list = range(0,a)\n",
        "num_dev = 27 # number of devices considered in the FL\n",
        "allocate_dev = np.array_split(a_index_list,num_dev) # how to distribute training data among all devices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcjbz53VM1xX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a34355f-9ba7-489d-d2d1-698598179a50"
      },
      "source": [
        "allocate_dev[17].size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "76"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bt0On3_jM54m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afe3e09e-439e-451f-b61a-4ac9f0e3bdf5"
      },
      "source": [
        "# model\n",
        "model_global = Net1d(modes, width).cuda()\n",
        "print(model_global.count_params())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "549569\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvLS5qgGvdqp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e03c1d0-99ee-4112-b59d-4ffe45459299"
      },
      "source": [
        "model = model_global\n",
        "w1 = []\n",
        "w1 = model_global.conv1.fc0.weight\n",
        "w2 = model_global.conv1.fc0.weight\n",
        "w1.size()\n",
        "#model2 = Net1d(modes, width).cuda()\n",
        "#model2.conv1.fc0.weight = torch.nn.Parameter(w_final)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRf6aoOdGtD1",
        "outputId": "10d3002f-c133-4dba-8e0e-f0a6e32d6293"
      },
      "source": [
        "model_global.conv1.conv0.weights1.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 64, 16, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "644msbO6ZfZ8"
      },
      "source": [
        "dev_data_range = allocate_dev[0]\n",
        "dev_data_size = dev_data_range.size\n",
        "x_train = x_data[dev_data_range[0]:dev_data_range[-1]+1,:]\n",
        "y_train = y_data[dev_data_range[0]:dev_data_range[-1]+1,:]\n",
        "# x_train\n",
        "# cat the locations information\n",
        "grid = np.linspace(0, 2*np.pi, s).reshape(1, s, 1)\n",
        "grid = torch.tensor(grid, dtype=torch.float)\n",
        "x_train = torch.cat([x_train.reshape(dev_data_size,s,1), grid.repeat(dev_data_size,1,1)], dim=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqDmX3R2wiuG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXSlbp_7bM57"
      },
      "source": [
        "aa = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_data, y_data), batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_ZFR-suyTnpn",
        "outputId": "5cfaf379-cc0d-4581-f9fc-3cea78af6db1"
      },
      "source": [
        "# Here is how optimization works here\n",
        "# myloss = LpLoss(size_average=False)\n",
        "for ep in range(rounds):\n",
        "  t1 = default_timer()\n",
        "  train_mse = 0\n",
        "  train_l2 = 0\n",
        "\n",
        "  w_conv1_fc0_weight = torch.zeros(model_global.conv1.fc0.weight.size()).to('cuda:0')\n",
        "  w_conv1_fc0_bias = torch.zeros(model_global.conv1.fc0.bias.size()).to('cuda:0')\n",
        "  w_conv1_conv0_weights1 = torch.zeros(model_global.conv1.conv0.weights1.size()).to('cuda:0')\n",
        "  w_conv1_conv1_weights1 = torch.zeros(model_global.conv1.conv1.weights1.size()).to('cuda:0')\n",
        "  w_conv1_conv2_weights1 = torch.zeros(model_global.conv1.conv2.weights1.size()).to('cuda:0')\n",
        "  w_conv1_conv3_weights1 = torch.zeros(model_global.conv1.conv3.weights1.size()).to('cuda:0')\n",
        "  w_conv1_w0_weight = torch.zeros(model_global.conv1.w0.weight.size()).to('cuda:0')\n",
        "  w_conv1_w0_bias = torch.zeros(model_global.conv1.w0.bias.size()).to('cuda:0')\n",
        "  w_conv1_w1_weight = torch.zeros(model_global.conv1.w1.weight.size()).to('cuda:0')\n",
        "  w_conv1_w1_bias = torch.zeros(model_global.conv1.w1.bias.size()).to('cuda:0')\n",
        "  w_conv1_w2_weight = torch.zeros(model_global.conv1.w2.weight.size()).to('cuda:0')\n",
        "  w_conv1_w2_bias = torch.zeros(model_global.conv1.w2.bias.size()).to('cuda:0')\n",
        "  w_conv1_w3_weight = torch.zeros(model_global.conv1.w3.weight.size()).to('cuda:0')\n",
        "  w_conv1_w3_bias = torch.zeros(model_global.conv1.w3.bias.size()).to('cuda:0')\n",
        "  w_conv1_fc1_weight = torch.zeros(model_global.conv1.fc1.weight.size()).to('cuda:0')\n",
        "  w_conv1_fc1_bias = torch.zeros(model_global.conv1.fc1.bias.size()).to('cuda:0')\n",
        "  w_conv1_fc2_weight = torch.zeros(model_global.conv1.fc2.weight.size()).to('cuda:0')\n",
        "  w_conv1_fc2_bias = torch.zeros(model_global.conv1.fc2.bias.size()).to('cuda:0')\n",
        "  for dev_index in range(num_dev):\n",
        "    dev_data_range = allocate_dev[dev_index]\n",
        "    dev_data_size = dev_data_range.size\n",
        "    x_train = x_data[dev_data_range[0]:dev_data_range[-1]+1,:]\n",
        "    y_train = y_data[dev_data_range[0]:dev_data_range[-1]+1,:]\n",
        "\n",
        "    # cat the locations information\n",
        "    grid = np.linspace(0, 2*np.pi, s).reshape(1, s, 1)\n",
        "    grid = torch.tensor(grid, dtype=torch.float)\n",
        "    x_train = torch.cat([x_train.reshape(dev_data_size,s,1), grid.repeat(dev_data_size,1,1)], dim=2)\n",
        "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "    model = model_global\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "    model.train()\n",
        "    for x, y in train_loader:\n",
        "        x, y = x.cuda(), y.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "\n",
        "        mse = F.mse_loss(out, y, reduction='mean')\n",
        "        mse.backward()\n",
        "        #l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
        "        #l2.backward() # use the l2 relative losa\n",
        "        optimizer.step()\n",
        "        train_mse += mse.item()\n",
        "        #train_l2 += l2.item()\n",
        "    #print(train_mse)\n",
        "    scheduler.step()\n",
        "    w_conv1_fc0_weight += model.conv1.fc0.weight\n",
        "    #print(w_conv1_fc0_weight)\n",
        "    w_conv1_fc0_bias += model.conv1.fc0.bias\n",
        "    w_conv1_conv0_weights1 += model.conv1.conv0.weights1\n",
        "    w_conv1_conv1_weights1 += model.conv1.conv1.weights1\n",
        "    w_conv1_conv2_weights1 += model.conv1.conv2.weights1\n",
        "    w_conv1_conv3_weights1 += model.conv1.conv3.weights1\n",
        "    w_conv1_w0_weight += model.conv1.w0.weight\n",
        "    w_conv1_w0_bias += model.conv1.w0.bias\n",
        "    w_conv1_w1_weight += model.conv1.w1.weight\n",
        "    w_conv1_w1_bias += model.conv1.w1.bias\n",
        "    w_conv1_w2_weight += model.conv1.w2.weight\n",
        "    w_conv1_w2_bias += model.conv1.w2.bias\n",
        "    w_conv1_w3_weight += model.conv1.w3.weight\n",
        "    w_conv1_w3_bias += model.conv1.w3.bias\n",
        "    w_conv1_fc1_weight += model.conv1.fc1.weight\n",
        "    w_conv1_fc1_bias += model.conv1.fc1.bias\n",
        "    w_conv1_fc2_weight += model.conv1.fc2.weight\n",
        "    w_conv1_fc2_bias += model.conv1.fc2.bias\n",
        "    '''\n",
        "    scheduler.step()\n",
        "    model.eval()\n",
        "    test_l2 = 0.0\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.cuda(), y.cuda()\n",
        "\n",
        "            out = model(x)\n",
        "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
        "\n",
        "    train_mse /= len(train_loader)\n",
        "    train_l2 /= ntrain\n",
        "    test_l2 /= ntest\n",
        "    '''\n",
        "  w_conv1_fc0_weight_final = torch.mul(w_conv1_fc0_weight,1/num_dev)\n",
        "  #print(w_conv1_fc0_weight_final)\n",
        "  w_conv1_fc0_bias_final = torch.mul(w_conv1_fc0_bias,1/num_dev)\n",
        "  w_conv1_conv0_weights1_final = torch.mul(w_conv1_conv0_weights1,1/num_dev)\n",
        "  w_conv1_conv1_weights1_final = torch.mul(w_conv1_conv1_weights1,1/num_dev)\n",
        "  w_conv1_conv2_weights1_final = torch.mul(w_conv1_conv2_weights1,1/num_dev)\n",
        "  w_conv1_conv3_weights1_final = torch.mul(w_conv1_conv3_weights1,1/num_dev)\n",
        "  w_conv1_w0_weight_final = torch.mul(w_conv1_w0_weight,1/num_dev)\n",
        "  w_conv1_w0_bias_final = torch.mul(w_conv1_w0_bias,1/num_dev)\n",
        "  w_conv1_w1_weight_final = torch.mul(w_conv1_w1_weight,1/num_dev)\n",
        "  w_conv1_w1_bias_final = torch.mul(w_conv1_w1_bias,1/num_dev)\n",
        "  w_conv1_w2_weight_final = torch.mul(w_conv1_w2_weight,1/num_dev)\n",
        "  w_conv1_w2_bias_final = torch.mul(w_conv1_w2_bias,1/num_dev)\n",
        "  w_conv1_w3_weight_final = torch.mul(w_conv1_w3_weight,1/num_dev)\n",
        "  w_conv1_w3_bias_final = torch.mul(w_conv1_w3_bias,1/num_dev)\n",
        "  w_conv1_fc1_weight_final = torch.mul(w_conv1_fc1_weight,1/num_dev)\n",
        "  w_conv1_fc1_bias_final = torch.mul(w_conv1_fc1_bias,1/num_dev)\n",
        "  w_conv1_fc2_weight_final = torch.mul(w_conv1_fc2_weight,1/num_dev)\n",
        "  w_conv1_fc2_bias_final = torch.mul(w_conv1_fc2_bias,1/num_dev)\n",
        "  model_global = Net1d(modes, width).cuda()\n",
        "  model_global.conv1.fc0.weight = torch.nn.Parameter(w_conv1_fc0_weight_final)\n",
        "  #print(model_global.conv1.fc0.weight)\n",
        "  model_global.conv1.fc0.bias = torch.nn.Parameter(w_conv1_fc0_bias_final)\n",
        "  model_global.conv1.conv0.weights1 = torch.nn.Parameter(w_conv1_conv0_weights1_final)\n",
        "  model_global.conv1.conv1.weights1 = torch.nn.Parameter(w_conv1_conv1_weights1_final)\n",
        "  model_global.conv1.conv2.weights1 = torch.nn.Parameter(w_conv1_conv2_weights1_final)\n",
        "  model_global.conv1.conv3.weights1 = torch.nn.Parameter(w_conv1_conv3_weights1_final)\n",
        "  model_global.conv1.w0.weight = torch.nn.Parameter(w_conv1_w0_weight_final)\n",
        "  model_global.conv1.w0.bias = torch.nn.Parameter(w_conv1_w0_bias_final)\n",
        "  model_global.conv1.w1.weight = torch.nn.Parameter(w_conv1_w1_weight_final)\n",
        "  model_global.conv1.w1.bias = torch.nn.Parameter(w_conv1_w1_bias_final)\n",
        "  model_global.conv1.w2.weight = torch.nn.Parameter(w_conv1_w2_weight_final)\n",
        "  model_global.conv1.w2.bias = torch.nn.Parameter(w_conv1_w2_bias_final)\n",
        "  model_global.conv1.w3.weight = torch.nn.Parameter(w_conv1_w3_weight_final)\n",
        "  model_global.conv1.w3.bias = torch.nn.Parameter(w_conv1_w3_bias_final)\n",
        "  model_global.conv1.fc1.weight = torch.nn.Parameter(w_conv1_fc1_weight_final)\n",
        "  model_global.conv1.fc1.bias = torch.nn.Parameter(w_conv1_fc1_bias_final)\n",
        "  model_global.conv1.fc2.weight = torch.nn.Parameter(w_conv1_fc2_weight_final)\n",
        "  model_global.conv1.fc2.bias = torch.nn.Parameter(w_conv1_fc2_bias_final)\n",
        "  t2 = default_timer()\n",
        "  #aa = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_data, y_data), batch_size=batch_size, shuffle=True)\n",
        "  print(ep, t2-t1, train_mse/27)\n",
        "  #print(model.conv1.fc0.weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:590.)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:26: UserWarning: The function torch.irfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.irfft. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:602.)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 2.763574888000022 0.16613995093265893\n",
            "1 2.7377015749999885 0.05929271161073336\n",
            "2 2.7840030480000166 0.041990578357837406\n",
            "3 2.700624470000008 0.03926311652564133\n",
            "4 2.7367974120000156 0.03186697559000028\n",
            "5 2.839335707999993 0.028054355874903396\n",
            "6 2.7674628729999995 0.028132430670127547\n",
            "7 2.7416887669999994 0.0235932881629129\n",
            "8 2.7108042570000066 0.02135407753101188\n",
            "9 2.765325770000004 0.019275711328696668\n",
            "10 2.7572227610000084 0.018385209974237822\n",
            "11 2.774357205000001 0.01891287346909478\n",
            "12 2.743030327000014 0.017341310460189427\n",
            "13 2.7505975789999866 0.015718243373730394\n",
            "14 2.777307307000001 0.015959791236565688\n",
            "15 2.79163041999999 0.014546813829198342\n",
            "16 2.736462305999993 0.014131916533827919\n",
            "17 2.698691927999988 0.012908756662336937\n",
            "18 2.6985709250000127 0.012357969702592257\n",
            "19 2.766386787999977 0.012421305135056307\n",
            "20 2.7097609839999564 0.01227850595239067\n",
            "21 2.6844917399999986 0.011350262501057133\n",
            "22 2.706031429999996 0.010947319299534516\n",
            "23 2.7395569569999907 0.010864578619172486\n",
            "24 2.7139652049999654 0.011229829847622939\n",
            "25 2.7273241020000114 0.010168698216956627\n",
            "26 2.802196637999998 0.011235801403893641\n",
            "27 2.7160374619999743 0.010438618096587662\n",
            "28 2.7398007279999774 0.010083679870823052\n",
            "29 2.7409994159999655 0.010152727145598166\n",
            "30 2.757769320999955 0.010027297381721265\n",
            "31 2.8016852000000085 0.009557577825573928\n",
            "32 2.7637528839999845 0.009857791709321275\n",
            "33 2.758291434 0.010194620800407225\n",
            "34 2.7548876949999794 0.008995601547886272\n",
            "35 2.7243234069999858 0.008745091361493838\n",
            "36 2.7295219469999665 0.00967130224954518\n",
            "37 2.7203378560000147 0.008907538616094153\n",
            "38 2.760213531999966 0.009952341574481343\n",
            "39 2.7209119749999786 0.007734898719246741\n",
            "40 2.692008539000028 0.00977485742003881\n",
            "41 2.740927213999953 0.008751782585426958\n",
            "42 2.755341842000007 0.009458270058665355\n",
            "43 2.807703265999976 0.008561654314420323\n",
            "44 2.7534301320000054 0.008701075158131533\n",
            "45 2.7620972170000186 0.008790015689791526\n",
            "46 2.7623019100000192 0.008329029238127448\n",
            "47 2.691649957999971 0.008086627186222122\n",
            "48 2.704379380999967 0.007550550645208676\n",
            "49 2.7088909799999783 0.007398874186846014\n",
            "50 2.7750149100000385 0.0077674288019167126\n",
            "51 2.7487404519999927 0.00792111579923787\n",
            "52 2.735839232000046 0.007437270404436815\n",
            "53 2.7009374269999853 0.007590540060105182\n",
            "54 2.7389845769999965 0.007664838465172108\n",
            "55 2.7037543259999666 0.008610994860376834\n",
            "56 2.718629610999983 0.0066947431095522245\n",
            "57 2.7460487379999563 0.007486160944810965\n",
            "58 2.7090381779999575 0.007586272129965773\n",
            "59 2.7657935629999884 0.007364863728677544\n",
            "60 2.7823520800000097 0.0071230319116255955\n",
            "61 2.737681863999967 0.007317518887618833\n",
            "62 2.7999064960000055 0.007518658253603563\n",
            "63 2.7671637270000247 0.006890654858445352\n",
            "64 2.7650509100000136 0.007173622495934574\n",
            "65 2.7087862850000306 0.007245835002524675\n",
            "66 2.7422913790000507 0.007048840103649396\n",
            "67 2.7524667700000123 0.007735346987492112\n",
            "68 2.7229374320000375 0.006386376392684825\n",
            "69 2.724531603999992 0.006979070845570984\n",
            "70 2.727913134000005 0.007365038437354896\n",
            "71 2.749900069999967 0.006935753525154993\n",
            "72 2.7386588340000344 0.006874303101708561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-7b5a9de91f0b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mmse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m#l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2649\u001b[0m                 \u001b[0mmse_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtens_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m                 reduction=reduction)\n\u001b[0;32m-> 2651\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2652\u001b[0m         warnings.warn(\"Using a target size ({}) that is different to the input size ({}). \"\n\u001b[1;32m   2653\u001b[0m                       \u001b[0;34m\"This will likely lead to incorrect results due to broadcasting. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TL78CgpHI_6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}